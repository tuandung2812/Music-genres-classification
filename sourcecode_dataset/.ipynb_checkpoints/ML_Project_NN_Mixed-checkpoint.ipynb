{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading mixed data (GTZAN dataset + YouTube data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MFCC1_Mean</th>\n",
       "      <th>MFCC2_Mean</th>\n",
       "      <th>MFCC3_Mean</th>\n",
       "      <th>MFCC4_Mean</th>\n",
       "      <th>MFCC5_Mean</th>\n",
       "      <th>MFCC6_Mean</th>\n",
       "      <th>MFCC7_Mean</th>\n",
       "      <th>MFCC8_Mean</th>\n",
       "      <th>MFCC9_Mean</th>\n",
       "      <th>MFCC10_Mean</th>\n",
       "      <th>...</th>\n",
       "      <th>MFCC12_Var</th>\n",
       "      <th>MFCC13_Var</th>\n",
       "      <th>MFCC14_Var</th>\n",
       "      <th>MFCC15_Var</th>\n",
       "      <th>MFCC16_Var</th>\n",
       "      <th>MFCC17_Var</th>\n",
       "      <th>MFCC18_Var</th>\n",
       "      <th>MFCC19_Var</th>\n",
       "      <th>MFCC20_Var</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-202.407974</td>\n",
       "      <td>166.767883</td>\n",
       "      <td>-29.063051</td>\n",
       "      <td>35.231968</td>\n",
       "      <td>-7.021881</td>\n",
       "      <td>26.260551</td>\n",
       "      <td>-12.185494</td>\n",
       "      <td>15.810824</td>\n",
       "      <td>-4.190476</td>\n",
       "      <td>-6.121345</td>\n",
       "      <td>...</td>\n",
       "      <td>35.144840</td>\n",
       "      <td>63.236923</td>\n",
       "      <td>47.332485</td>\n",
       "      <td>86.354355</td>\n",
       "      <td>38.870907</td>\n",
       "      <td>94.355904</td>\n",
       "      <td>18.192657</td>\n",
       "      <td>58.465191</td>\n",
       "      <td>43.517445</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-194.815598</td>\n",
       "      <td>170.630585</td>\n",
       "      <td>-37.334534</td>\n",
       "      <td>36.500557</td>\n",
       "      <td>-6.618162</td>\n",
       "      <td>18.045141</td>\n",
       "      <td>-6.102125</td>\n",
       "      <td>15.924576</td>\n",
       "      <td>-3.994879</td>\n",
       "      <td>-5.965096</td>\n",
       "      <td>...</td>\n",
       "      <td>41.252335</td>\n",
       "      <td>39.127922</td>\n",
       "      <td>50.740669</td>\n",
       "      <td>57.180687</td>\n",
       "      <td>62.119591</td>\n",
       "      <td>62.943115</td>\n",
       "      <td>69.166725</td>\n",
       "      <td>123.617004</td>\n",
       "      <td>72.833069</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-207.168427</td>\n",
       "      <td>177.416641</td>\n",
       "      <td>-19.825985</td>\n",
       "      <td>34.417259</td>\n",
       "      <td>-13.723843</td>\n",
       "      <td>22.251123</td>\n",
       "      <td>-8.538532</td>\n",
       "      <td>12.130745</td>\n",
       "      <td>-0.924732</td>\n",
       "      <td>-4.370468</td>\n",
       "      <td>...</td>\n",
       "      <td>47.653198</td>\n",
       "      <td>37.141811</td>\n",
       "      <td>32.786049</td>\n",
       "      <td>61.379265</td>\n",
       "      <td>31.179749</td>\n",
       "      <td>35.971004</td>\n",
       "      <td>32.982254</td>\n",
       "      <td>32.468094</td>\n",
       "      <td>22.021683</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-173.847214</td>\n",
       "      <td>138.374161</td>\n",
       "      <td>-31.265633</td>\n",
       "      <td>50.847828</td>\n",
       "      <td>-24.704271</td>\n",
       "      <td>17.972462</td>\n",
       "      <td>-1.393162</td>\n",
       "      <td>-4.374794</td>\n",
       "      <td>-7.386628</td>\n",
       "      <td>15.041191</td>\n",
       "      <td>...</td>\n",
       "      <td>74.775719</td>\n",
       "      <td>46.816250</td>\n",
       "      <td>87.237602</td>\n",
       "      <td>64.124466</td>\n",
       "      <td>99.918686</td>\n",
       "      <td>77.069939</td>\n",
       "      <td>49.496777</td>\n",
       "      <td>146.983185</td>\n",
       "      <td>36.357033</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-178.541718</td>\n",
       "      <td>151.246490</td>\n",
       "      <td>-37.812202</td>\n",
       "      <td>47.722809</td>\n",
       "      <td>-7.711584</td>\n",
       "      <td>18.562996</td>\n",
       "      <td>-5.909832</td>\n",
       "      <td>7.504122</td>\n",
       "      <td>-7.322074</td>\n",
       "      <td>11.085575</td>\n",
       "      <td>...</td>\n",
       "      <td>34.002884</td>\n",
       "      <td>35.557098</td>\n",
       "      <td>87.806839</td>\n",
       "      <td>78.256432</td>\n",
       "      <td>99.967041</td>\n",
       "      <td>64.290489</td>\n",
       "      <td>68.170197</td>\n",
       "      <td>41.308800</td>\n",
       "      <td>55.424549</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MFCC1_Mean  MFCC2_Mean  MFCC3_Mean  MFCC4_Mean  MFCC5_Mean  MFCC6_Mean  \\\n",
       "0 -202.407974  166.767883  -29.063051   35.231968   -7.021881   26.260551   \n",
       "1 -194.815598  170.630585  -37.334534   36.500557   -6.618162   18.045141   \n",
       "2 -207.168427  177.416641  -19.825985   34.417259  -13.723843   22.251123   \n",
       "3 -173.847214  138.374161  -31.265633   50.847828  -24.704271   17.972462   \n",
       "4 -178.541718  151.246490  -37.812202   47.722809   -7.711584   18.562996   \n",
       "\n",
       "   MFCC7_Mean  MFCC8_Mean  MFCC9_Mean  MFCC10_Mean  ...  MFCC12_Var  \\\n",
       "0  -12.185494   15.810824   -4.190476    -6.121345  ...   35.144840   \n",
       "1   -6.102125   15.924576   -3.994879    -5.965096  ...   41.252335   \n",
       "2   -8.538532   12.130745   -0.924732    -4.370468  ...   47.653198   \n",
       "3   -1.393162   -4.374794   -7.386628    15.041191  ...   74.775719   \n",
       "4   -5.909832    7.504122   -7.322074    11.085575  ...   34.002884   \n",
       "\n",
       "   MFCC13_Var  MFCC14_Var  MFCC15_Var  MFCC16_Var  MFCC17_Var  MFCC18_Var  \\\n",
       "0   63.236923   47.332485   86.354355   38.870907   94.355904   18.192657   \n",
       "1   39.127922   50.740669   57.180687   62.119591   62.943115   69.166725   \n",
       "2   37.141811   32.786049   61.379265   31.179749   35.971004   32.982254   \n",
       "3   46.816250   87.237602   64.124466   99.918686   77.069939   49.496777   \n",
       "4   35.557098   87.806839   78.256432   99.967041   64.290489   68.170197   \n",
       "\n",
       "   MFCC19_Var  MFCC20_Var  Label  \n",
       "0   58.465191   43.517445  blues  \n",
       "1  123.617004   72.833069  blues  \n",
       "2   32.468094   22.021683  blues  \n",
       "3  146.983185   36.357033  blues  \n",
       "4   41.308800   55.424549  blues  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data_mix.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {'blues': 0, 'classical': 1, 'country': 2, 'disco': 3, 'hiphop': 4, 'jazz': 5, 'metal': 6, 'pop': 7, 'reggae': 8, 'rock': 9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(frac=1, random_state = 101).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = data[data.columns[:-1]]\n",
    "y_data = pd.Categorical(data['Label']).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_x = x_data.shape[0]\n",
    "x_train  = x_data[:math.floor(len_x * 0.85)]\n",
    "x_val  = x_data[math.floor(len_x * 0.85) :]\n",
    "\n",
    "len_y = y_data.shape[0]\n",
    "y_train  = y_data[:math.floor(len_y * 0.85)]\n",
    "y_val  = y_data[math.floor(len_y * 0.85) :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "scaled_tr = scaler.fit_transform(x_train)\n",
    "x_train = pd.DataFrame(scaled_tr, columns=x_train.columns)\n",
    "\n",
    "scaled_val = scaler.fit_transform(x_val)\n",
    "x_val = pd.DataFrame(scaled_val, columns=x_val.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 512)               20992     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 160,874\n",
      "Trainable params: 160,874\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(keras.layers.Dense(512, activation='relu', input_shape=(x_train.shape[1],)))\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "model.add(keras.layers.Dense(256, activation= 'relu'))\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "model.add(keras.layers.Dense(32, activation= 'relu'))\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "\n",
    "model.add(keras.layers.Dense(10, activation= 'softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "200/200 [==============================] - 2s 7ms/step - loss: 2.1700 - accuracy: 0.2166 - val_loss: 1.7211 - val_accuracy: 0.3778\n",
      "Epoch 2/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 1.7630 - accuracy: 0.3790 - val_loss: 1.5392 - val_accuracy: 0.4813\n",
      "Epoch 3/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 1.6191 - accuracy: 0.4351 - val_loss: 1.4454 - val_accuracy: 0.5284\n",
      "Epoch 4/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 1.5454 - accuracy: 0.4650 - val_loss: 1.3826 - val_accuracy: 0.5431\n",
      "Epoch 5/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 1.4611 - accuracy: 0.4956 - val_loss: 1.3225 - val_accuracy: 0.5756\n",
      "Epoch 6/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 1.4171 - accuracy: 0.5125 - val_loss: 1.2792 - val_accuracy: 0.5827\n",
      "Epoch 7/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 1.3688 - accuracy: 0.5313 - val_loss: 1.2425 - val_accuracy: 0.5960\n",
      "Epoch 8/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 1.3379 - accuracy: 0.5371 - val_loss: 1.2150 - val_accuracy: 0.6093\n",
      "Epoch 9/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 1.3222 - accuracy: 0.5447 - val_loss: 1.1853 - val_accuracy: 0.6169\n",
      "Epoch 10/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 1.2705 - accuracy: 0.5670 - val_loss: 1.1668 - val_accuracy: 0.6200\n",
      "Epoch 11/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 1.2539 - accuracy: 0.5745 - val_loss: 1.1433 - val_accuracy: 0.6298\n",
      "Epoch 12/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 1.2461 - accuracy: 0.5724 - val_loss: 1.1303 - val_accuracy: 0.6236\n",
      "Epoch 13/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 1.2126 - accuracy: 0.5897 - val_loss: 1.1123 - val_accuracy: 0.6298\n",
      "Epoch 14/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 1.2043 - accuracy: 0.5913 - val_loss: 1.1019 - val_accuracy: 0.6338\n",
      "Epoch 15/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 1.1728 - accuracy: 0.5981 - val_loss: 1.0844 - val_accuracy: 0.6391\n",
      "Epoch 16/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 1.1489 - accuracy: 0.6023 - val_loss: 1.0769 - val_accuracy: 0.6418\n",
      "Epoch 17/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 1.1509 - accuracy: 0.6135 - val_loss: 1.0577 - val_accuracy: 0.6462\n",
      "Epoch 18/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 1.1209 - accuracy: 0.6205 - val_loss: 1.0505 - val_accuracy: 0.6489\n",
      "Epoch 19/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 1.1150 - accuracy: 0.6193 - val_loss: 1.0323 - val_accuracy: 0.6573\n",
      "Epoch 20/200\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.1063 - accuracy: 0.6142 - val_loss: 1.0311 - val_accuracy: 0.6564\n",
      "Epoch 21/200\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.0870 - accuracy: 0.6280 - val_loss: 1.0156 - val_accuracy: 0.6569\n",
      "Epoch 22/200\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.0825 - accuracy: 0.6259 - val_loss: 1.0117 - val_accuracy: 0.6604\n",
      "Epoch 23/200\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.0705 - accuracy: 0.6381 - val_loss: 1.0013 - val_accuracy: 0.6627\n",
      "Epoch 24/200\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.0380 - accuracy: 0.6479 - val_loss: 0.9948 - val_accuracy: 0.6653\n",
      "Epoch 25/200\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0506 - accuracy: 0.6430 - val_loss: 0.9820 - val_accuracy: 0.6702\n",
      "Epoch 26/200\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0437 - accuracy: 0.6400 - val_loss: 0.9747 - val_accuracy: 0.6724\n",
      "Epoch 27/200\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0410 - accuracy: 0.6373 - val_loss: 0.9690 - val_accuracy: 0.6804\n",
      "Epoch 28/200\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0095 - accuracy: 0.6515 - val_loss: 0.9681 - val_accuracy: 0.6760\n",
      "Epoch 29/200\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0041 - accuracy: 0.6554 - val_loss: 0.9545 - val_accuracy: 0.6764\n",
      "Epoch 30/200\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9863 - accuracy: 0.6613 - val_loss: 0.9461 - val_accuracy: 0.6836\n",
      "Epoch 31/200\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.9609 - accuracy: 0.6724 - val_loss: 0.9407 - val_accuracy: 0.6818\n",
      "Epoch 32/200\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.9784 - accuracy: 0.6615 - val_loss: 0.9370 - val_accuracy: 0.6844\n",
      "Epoch 33/200\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.9526 - accuracy: 0.6716 - val_loss: 0.9309 - val_accuracy: 0.6858\n",
      "Epoch 34/200\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9412 - accuracy: 0.6723 - val_loss: 0.9249 - val_accuracy: 0.6884\n",
      "Epoch 35/200\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9354 - accuracy: 0.6775 - val_loss: 0.9219 - val_accuracy: 0.6920\n",
      "Epoch 36/200\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9403 - accuracy: 0.6718 - val_loss: 0.9157 - val_accuracy: 0.6924\n",
      "Epoch 37/200\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9418 - accuracy: 0.6797 - val_loss: 0.9129 - val_accuracy: 0.6924\n",
      "Epoch 38/200\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8989 - accuracy: 0.6905 - val_loss: 0.9061 - val_accuracy: 0.6938\n",
      "Epoch 39/200\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9168 - accuracy: 0.6833 - val_loss: 0.9041 - val_accuracy: 0.6911\n",
      "Epoch 40/200\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8918 - accuracy: 0.6919 - val_loss: 0.8902 - val_accuracy: 0.6947\n",
      "Epoch 41/200\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8767 - accuracy: 0.6937 - val_loss: 0.8864 - val_accuracy: 0.6987\n",
      "Epoch 42/200\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9045 - accuracy: 0.6969 - val_loss: 0.8846 - val_accuracy: 0.7013\n",
      "Epoch 43/200\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.8855 - accuracy: 0.6998 - val_loss: 0.8787 - val_accuracy: 0.7036\n",
      "Epoch 44/200\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8793 - accuracy: 0.7000 - val_loss: 0.8761 - val_accuracy: 0.7000\n",
      "Epoch 45/200\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8560 - accuracy: 0.7114 - val_loss: 0.8684 - val_accuracy: 0.7053\n",
      "Epoch 46/200\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8694 - accuracy: 0.7009 - val_loss: 0.8717 - val_accuracy: 0.7044\n",
      "Epoch 47/200\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8305 - accuracy: 0.7175 - val_loss: 0.8602 - val_accuracy: 0.7071\n",
      "Epoch 48/200\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8417 - accuracy: 0.7132 - val_loss: 0.8574 - val_accuracy: 0.7093\n",
      "Epoch 49/200\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8358 - accuracy: 0.7088 - val_loss: 0.8489 - val_accuracy: 0.7080\n",
      "Epoch 50/200\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8241 - accuracy: 0.7243 - val_loss: 0.8497 - val_accuracy: 0.7120\n",
      "Epoch 51/200\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.8276 - accuracy: 0.7167 - val_loss: 0.8489 - val_accuracy: 0.7116\n",
      "Epoch 52/200\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8287 - accuracy: 0.7146 - val_loss: 0.8406 - val_accuracy: 0.7120\n",
      "Epoch 53/200\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8018 - accuracy: 0.7258 - val_loss: 0.8367 - val_accuracy: 0.7160\n",
      "Epoch 54/200\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8008 - accuracy: 0.7230 - val_loss: 0.8386 - val_accuracy: 0.7147\n",
      "Epoch 55/200\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8074 - accuracy: 0.7192 - val_loss: 0.8298 - val_accuracy: 0.7133\n",
      "Epoch 56/200\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7821 - accuracy: 0.7362 - val_loss: 0.8326 - val_accuracy: 0.7231\n",
      "Epoch 57/200\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7912 - accuracy: 0.7321 - val_loss: 0.8229 - val_accuracy: 0.7200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/200\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7719 - accuracy: 0.7407 - val_loss: 0.8202 - val_accuracy: 0.7178\n",
      "Epoch 59/200\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7829 - accuracy: 0.7333 - val_loss: 0.8218 - val_accuracy: 0.7191\n",
      "Epoch 60/200\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.7728 - accuracy: 0.7376 - val_loss: 0.8171 - val_accuracy: 0.7178\n",
      "Epoch 61/200\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.7644 - accuracy: 0.7386 - val_loss: 0.8148 - val_accuracy: 0.7227\n",
      "Epoch 62/200\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.7594 - accuracy: 0.7414 - val_loss: 0.8092 - val_accuracy: 0.7200\n",
      "Epoch 63/200\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.7608 - accuracy: 0.7414 - val_loss: 0.8026 - val_accuracy: 0.7284\n",
      "Epoch 64/200\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7607 - accuracy: 0.7394 - val_loss: 0.8072 - val_accuracy: 0.7249\n",
      "Epoch 65/200\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.7363 - accuracy: 0.7486 - val_loss: 0.8022 - val_accuracy: 0.7209\n",
      "Epoch 66/200\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.7512 - accuracy: 0.7450 - val_loss: 0.8018 - val_accuracy: 0.7267\n",
      "Epoch 67/200\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.7315 - accuracy: 0.7467 - val_loss: 0.7941 - val_accuracy: 0.7329\n",
      "Epoch 68/200\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.7286 - accuracy: 0.7498 - val_loss: 0.7890 - val_accuracy: 0.7320\n",
      "Epoch 69/200\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7293 - accuracy: 0.7479 - val_loss: 0.7854 - val_accuracy: 0.7329\n",
      "Epoch 70/200\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.7124 - accuracy: 0.7537 - val_loss: 0.7865 - val_accuracy: 0.7347\n",
      "Epoch 71/200\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.7263 - accuracy: 0.7507 - val_loss: 0.7861 - val_accuracy: 0.7289\n",
      "Epoch 72/200\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7153 - accuracy: 0.7539 - val_loss: 0.7814 - val_accuracy: 0.7382\n",
      "Epoch 73/200\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6997 - accuracy: 0.7593 - val_loss: 0.7775 - val_accuracy: 0.7360\n",
      "Epoch 74/200\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.6919 - accuracy: 0.7660 - val_loss: 0.7764 - val_accuracy: 0.7400\n",
      "Epoch 75/200\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.6840 - accuracy: 0.7685 - val_loss: 0.7749 - val_accuracy: 0.7329\n",
      "Epoch 76/200\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.6902 - accuracy: 0.7693 - val_loss: 0.7770 - val_accuracy: 0.7356\n",
      "Epoch 77/200\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.6644 - accuracy: 0.7731 - val_loss: 0.7667 - val_accuracy: 0.7387\n",
      "Epoch 78/200\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.6617 - accuracy: 0.7756 - val_loss: 0.7699 - val_accuracy: 0.7413\n",
      "Epoch 79/200\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.6764 - accuracy: 0.7707 - val_loss: 0.7659 - val_accuracy: 0.7347\n",
      "Epoch 80/200\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.6863 - accuracy: 0.7674 - val_loss: 0.7666 - val_accuracy: 0.7427\n",
      "Epoch 81/200\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.6696 - accuracy: 0.7771 - val_loss: 0.7634 - val_accuracy: 0.7436\n",
      "Epoch 82/200\n",
      "140/200 [====================>.........] - ETA: 0s - loss: 0.6562 - accuracy: 0.7726"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = keras.optimizers.Adam(learning_rate = 0.0001),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "history = model.fit(x = x_train, y = y_train, validation_data= (x_val,y_val), epochs=200, batch_size = 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy & Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on YouTube data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_test = pd.read_csv('data_test.csv')\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test.Label = [classes[l] for l in data_test.Label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = data_test[data_test.columns[:-1]]\n",
    "y_test = data_test['Label']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_test = scaler.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_mtx = tf.math.confusion_matrix(y_test, model.predict_classes(x_test)) \n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(confusion_mtx, xticklabels=classes.keys(), yticklabels=classes.keys(), \n",
    "            annot=True, fmt='g')\n",
    "plt.xlabel('Prediction')\n",
    "plt.ylabel('Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/NN_Mixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
